{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f05c77d",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ruslanmv/Watsonx-Assistant-with-Milvus-as-Vector-Database/blob/master/notebooks/1_build_question_answering_engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e410b6c4",
   "metadata": {
    "id": "e410b6c4"
   },
   "source": [
    "# Build a Question Answering Engine in Minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed6f24",
   "metadata": {
    "id": "9bed6f24"
   },
   "source": [
    "This notebook illustrates how to build a question answering engine from scratch using [Milvus](https://milvus.io/) and [Towhee](https://towhee.io/). Milvus is the most advanced open-source vector database built for AI applications and supports nearest neighbor embedding search across tens of millions of entries, and Towhee is a framework that provides ETL for unstructured data using SoTA machine learning models.\n",
    "\n",
    "We will go through question answering procedures and evaluate performance. Moreover, we managed to make the core functionality as simple as almost 10 lines of code with Towhee, so that you can start hacking your own question answering engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883e577",
   "metadata": {
    "id": "4883e577"
   },
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49110b91",
   "metadata": {
    "id": "49110b91"
   },
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117995a",
   "metadata": {
    "id": "0117995a"
   },
   "source": [
    "First we need to install dependencies such as towhee, towhee.models and gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba3850",
   "metadata": {
    "id": "c9ba3850",
    "outputId": "64286339-3996-4317-c6c6-6582e74a8eec"
   },
   "outputs": [],
   "source": [
    "#!python3 -m pip install -q towhee towhee.models gradio torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90db0c5",
   "metadata": {
    "id": "a90db0c5"
   },
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eceb58",
   "metadata": {
    "id": "d1eceb58"
   },
   "source": [
    "There is a subset of the  [InsuranceQA Corpus](https://github.com/shuzi/insuranceQA)  (1000 pairs of questions and answers) used in this demo, everyone can download on [Github](https://github.com/towhee-io/examples/releases/download/data/question_answer.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1436a9c",
   "metadata": {
    "id": "d1436a9c",
    "outputId": "17c7f2ff-79fb-4b04-bcd5-79a048f8e4a9"
   },
   "outputs": [],
   "source": [
    "! curl -L https://github.com/towhee-io/examples/releases/download/data/question_answer.csv -O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abdc0a",
   "metadata": {
    "id": "c4abdc0a"
   },
   "source": [
    "**question_answer.csv**: a file containing question and the answer.\n",
    "\n",
    "Let's take a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652efea",
   "metadata": {
    "id": "d652efea",
    "outputId": "ee6fdd36-8205-40d0-b7b2-701c09f153f7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('question_answer.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309bfb43",
   "metadata": {
    "id": "309bfb43"
   },
   "source": [
    "To use the dataset to get answers, let's first define the dictionary:\n",
    "\n",
    "- `id_answer`: a dictionary of id and corresponding answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98b309",
   "metadata": {
    "id": "4d98b309"
   },
   "outputs": [],
   "source": [
    "id_answer = df.set_index('id')['answer'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a0858",
   "metadata": {
    "id": "1c5a0858"
   },
   "source": [
    "### Create Milvus Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb06a01",
   "metadata": {
    "id": "efb06a01"
   },
   "source": [
    "Before getting started, please make sure that you have started a [Milvus service](https://milvus.io/docs/install_standalone-docker.md). This notebook uses [milvus 2.2.10](https://milvus.io/docs/v2.2.x/install_standalone-docker.md) and [pymilvus 2.2.11](https://milvus.io/docs/release_notes.md#2210)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048bf6c",
   "metadata": {
    "id": "8048bf6c"
   },
   "outputs": [],
   "source": [
    "#!python3 -m pip install -q pymilvus==2.2.11 transformers ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba2b23",
   "metadata": {
    "id": "87ba2b23"
   },
   "source": [
    "Next to define the function `create_milvus_collection` to create collection in Milvus that uses the [L2 distance metric](https://milvus.io/docs/metric.md#Euclidean-distance-L2) and an [IVF_FLAT index](https://milvus.io/docs/index.md#IVF_FLAT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344421fe",
   "metadata": {},
   "source": [
    "### Setup Remote Server\n",
    "Here we should define the variable `REMOTE_SERVER` just created [here](https://github.com/ruslanmv/Watsonx-Assistant-with-Milvus-as-Vector-Database/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4105b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOTE_SERVER='50.17.92.90'\n",
    "LOCAL_SERVER='127.0.0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e15f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "connections.connect(host=REMOTE_SERVER, port='19530')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c19982",
   "metadata": {
    "id": "22c19982"
   },
   "outputs": [],
   "source": [
    "def create_milvus_collection(collection_name, dim):\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "\n",
    "    fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.VARCHAR, descrition='ids', max_length=500, is_primary=True, auto_id=False),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='reverse image search')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    # create IVF_FLAT index for collection.\n",
    "    index_params = {\n",
    "        'metric_type':'L2',\n",
    "        'index_type':\"IVF_FLAT\",\n",
    "        'params':{\"nlist\":2048}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    return collection\n",
    "\n",
    "collection = create_milvus_collection('question_answer', 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9724ba28",
   "metadata": {
    "id": "9724ba28"
   },
   "source": [
    "## Question Answering Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1ac7e",
   "metadata": {
    "id": "01e1ac7e"
   },
   "source": [
    "In this section, we will show how to build our question answering engine using Milvus and Towhee. The basic idea behind question answering is to use Towhee to generate embedding from the question dataset and compare the input question with the embedding stored in Milvus.\n",
    "\n",
    "[Towhee](https://towhee.io/) is a machine learning framework that allows the creation of data processing pipelines, and it also provides predefined operators for implementing insert and query operations in Milvus.\n",
    "\n",
    "<img src=\"./workflow.png\" width = \"60%\" height = \"60%\" align=center />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0188bf",
   "metadata": {
    "id": "4c0188bf"
   },
   "source": [
    "### Load question embedding into Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a654fdc",
   "metadata": {
    "id": "0a654fdc"
   },
   "source": [
    "We first generate embedding from question text with [dpr](https://towhee.io/text-embedding/dpr) operator and insert the embedding into Milvus. Towhee provides a [method-chaining style API](https://towhee.readthedocs.io/en/main/index.html) so that users can assemble a data processing pipeline with operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7beea",
   "metadata": {
    "id": "13b7beea",
    "outputId": "5152283b-025b-43f3-b0f3-215a174c285a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from towhee import pipe, ops\n",
    "import numpy as np\n",
    "from towhee.datacollection import DataCollection\n",
    "from IPython.display import clear_output\n",
    "insert_pipe = (\n",
    "    pipe.input('id', 'question', 'answer')\n",
    "        .map('question', 'vec', ops.text_embedding.dpr(model_name='facebook/dpr-ctx_encoder-single-nq-base'))\n",
    "        .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
    "        .map(('id', 'vec'), 'insert_status', ops.ann_insert.milvus_client(host=REMOTE_SERVER, port='19530', collection_name='question_answer'))\n",
    "        .output()\n",
    ")\n",
    "\n",
    "import csv\n",
    "with open('question_answer.csv', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        insert_pipe(*row)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbb2e1",
   "metadata": {
    "id": "1adbb2e1",
    "outputId": "b6dea15e-3ae8-4263-d6d3-7c1822b3ba19"
   },
   "outputs": [],
   "source": [
    "print('Total number of inserted data is {}.'.format(collection.num_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb269f4",
   "metadata": {
    "id": "deb269f4"
   },
   "source": [
    "#### Explanation of Data Processing Pipeline\n",
    "\n",
    "Here is detailed explanation for each line of the code:\n",
    "\n",
    "`pipe.input('id', 'question', 'answer')`: Get three inputs, namely question's id, quesion's text and question's answer;\n",
    "\n",
    "`map('question', 'vec', ops.text_embedding.dpr(model_name='facebook/dpr-ctx_encoder-single-nq-base'))`: Use the `acebook/dpr-ctx_encoder-single-nq-base` model to generate the question embedding vector with the [dpr operator](https://towhee.io/text-embedding/dpr) in towhee hub;\n",
    "\n",
    "`map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))`: normalize the embedding vector;\n",
    "\n",
    "`map(('id', 'vec'), 'insert_status', ops.ann_insert.milvus_client(host='127.0.0.1', port='19530', collection_name='question_answer'))`: insert question embedding vector into Milvus;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35657d0",
   "metadata": {
    "id": "b35657d0"
   },
   "source": [
    "### Ask Question with Milvus and Towhee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02adfc",
   "metadata": {
    "id": "cd02adfc"
   },
   "source": [
    "Now that embedding for question dataset have been inserted into Milvus, we can ask question with Milvus and Towhee. Again, we use Towhee to load the input question, compute a embedding, and use it as a query in Milvus. Because Milvus only outputs IDs and distance values, we provide the `id_answers` dictionary to get the answers based on IDs and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95913f05",
   "metadata": {
    "id": "95913f05",
    "outputId": "ae5ea48a-7bf2-4854-edb0-1ef018e77303"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "collection.load()\n",
    "ans_pipe = (\n",
    "    pipe.input('question')\n",
    "        .map('question', 'vec', ops.text_embedding.dpr(model_name=\"facebook/dpr-ctx_encoder-single-nq-base\"))\n",
    "        .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
    "        .map('vec', 'res', ops.ann_search.milvus_client(host=REMOTE_SERVER, port='19530', collection_name='question_answer', limit=1))\n",
    "        .map('res', 'answer', lambda x: [id_answer[int(i[0])] for i in x])\n",
    "        .output('question', 'answer')\n",
    ")\n",
    "ans = ans_pipe('Is  Disability  Insurance  Required  By  Law?')\n",
    "ans = DataCollection(ans)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d36b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb05a79",
   "metadata": {
    "id": "bfb05a79"
   },
   "source": [
    "Then we can get the answer about 'Is  Disability  Insurance  Required  By  Law?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a8f96",
   "metadata": {
    "id": "cb1a8f96",
    "outputId": "c19e3d2f-0e0b-47c5-ade8-85543543bdf8"
   },
   "outputs": [],
   "source": [
    "ans[0]['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bef722",
   "metadata": {
    "id": "01bef722"
   },
   "source": [
    "## Release a Showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71cace8",
   "metadata": {
    "id": "c71cace8"
   },
   "source": [
    "We've done an excellent job on the core functionality of our question answering engine. Now it's time to build a showcase with interface. [Gradio](https://gradio.app/) is a great tool for building demos. With Gradio, we simply need to wrap the data processing pipeline via a `chat` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d42114",
   "metadata": {
    "id": "65d42114"
   },
   "outputs": [],
   "source": [
    "import towhee\n",
    "def chat(message, history):\n",
    "    history = history or []\n",
    "    ans_pipe = (\n",
    "        pipe.input('question')\n",
    "            .map('question', 'vec', ops.text_embedding.dpr(model_name=\"facebook/dpr-ctx_encoder-single-nq-base\"))\n",
    "            .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
    "            .map('vec', 'res', ops.ann_search.milvus_client(host=REMOTE_SERVER, port='19530', collection_name='question_answer', limit=1))\n",
    "            .map('res', 'answer', lambda x: [id_answer[int(i[0])] for i in x])\n",
    "            .output('question', 'answer')\n",
    "    )\n",
    "    response = ans_pipe(message).get()[1][0]\n",
    "    history.append((message, response))\n",
    "    return history, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305a775-b467-40dc-9146-b6c490b55439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio\n",
    "\n",
    "collection.load()\n",
    "chatbot = gradio.Chatbot()\n",
    "interface = gradio.Interface(\n",
    "    chat,\n",
    "    [\"text\", \"state\"],\n",
    "    [chatbot, \"state\"],\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "clear_output()\n",
    "interface.launch(inline=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f9ebc1-d076-4493-859b-fc948d02d973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (watsonx)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7dd10cdbe9a9c71f7e71741efd428241b5f9fa0fecdd29ae07a5706cd5ff8a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
