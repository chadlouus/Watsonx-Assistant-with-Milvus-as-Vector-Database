{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ff6ab6",
   "metadata": {},
   "source": [
    "# WatsonX BackEnd Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883e577",
   "metadata": {
    "id": "4883e577"
   },
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117995a",
   "metadata": {
    "id": "0117995a"
   },
   "source": [
    "First we need to install dependencies such as towhee, towhee.models and gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba3850",
   "metadata": {
    "id": "c9ba3850",
    "outputId": "64286339-3996-4317-c6c6-6582e74a8eec"
   },
   "outputs": [],
   "source": [
    "! python -m pip install -q towhee towhee.models gradio datasets ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90db0c5",
   "metadata": {
    "id": "a90db0c5"
   },
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6999b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ruslanmv/ai-medical-chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abdc0a",
   "metadata": {
    "id": "c4abdc0a"
   },
   "source": [
    "**dataset**: a file containing question and the answer.\n",
    "\n",
    "Let's take a quick look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9be551",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = dataset[\"train\"].column_names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652efea",
   "metadata": {
    "id": "d652efea",
    "outputId": "ee6fdd36-8205-40d0-b7b2-701c09f153f7"
   },
   "outputs": [],
   "source": [
    "train_data = dataset[\"train\"]\n",
    "for i in range(1):\n",
    "    print(train_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e88cee",
   "metadata": {},
   "source": [
    "For this demo let us choose the first 1000 dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(train_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac441c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7330f1",
   "metadata": {},
   "source": [
    "For the development of the model, let just consider the patient and doctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[[\"Patient\", \"Doctor\"]].rename(columns={\"Patient\": \"question\", \"Doctor\": \"answer\"})\n",
    "df = df[[\"Description\", \"Doctor\"]].rename(columns={\"Description\": \"question\", \"Doctor\": \"answer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'ID' column as the first column\n",
    "df.insert(0, 'id', df.index)\n",
    "# Reset the index and drop the previous index column\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecbb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Clean the 'question' and 'answer' columns\n",
    "df['question'] = df['question'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "df['answer'] = df['answer'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "df['question'] = df['question'].str.replace('^Q.', '', regex=True)\n",
    "# Assuming your DataFrame is named df\n",
    "max_length = 500  # Due to our enbeeding model does not allow long strings\n",
    "df['question'] = df['question'].str.slice(0, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63484f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309bfb43",
   "metadata": {
    "id": "309bfb43"
   },
   "source": [
    "To use the dataset to get answers, let's first define the dictionary:\n",
    "\n",
    "- `id_answer`: a dictionary of id and corresponding answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_answer = df.set_index('id')['answer'].to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a0858",
   "metadata": {
    "id": "1c5a0858"
   },
   "source": [
    "### Create Milvus Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb06a01",
   "metadata": {
    "id": "efb06a01"
   },
   "source": [
    "Before getting started, please make sure that you have started a [Milvus service](https://milvus.io/docs/install_standalone-docker.md). This notebook uses [milvus 2.2.10](https://milvus.io/docs/v2.2.x/install_standalone-docker.md) and [pymilvus 2.2.11](https://milvus.io/docs/release_notes.md#2210)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048bf6c",
   "metadata": {
    "id": "8048bf6c"
   },
   "outputs": [],
   "source": [
    "! python -m pip install -q pymilvus==2.2.11 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba2b23",
   "metadata": {
    "id": "87ba2b23"
   },
   "source": [
    "Next to define the function `create_milvus_collection` to create collection in Milvus that uses the [L2 distance metric](https://milvus.io/docs/metric.md#Euclidean-distance-L2) and an [IVF_FLAT index](https://milvus.io/docs/index.md#IVF_FLAT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344421fe",
   "metadata": {},
   "source": [
    "### Setup Remote Server\n",
    "Here we should define the variable `REMOTE_SERVER` just created [here](https://github.com/ruslanmv/Watsonx-Assistant-with-Milvus-as-Vector-Database/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4105b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_SERVER='127.0.0.1'\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "host_milvus = os.environ.get(\"REMOTE_SERVER\", LOCAL_SERVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e15f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "connections.connect(host=host_milvus, port='19530')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c19982",
   "metadata": {
    "id": "22c19982"
   },
   "outputs": [],
   "source": [
    "def create_milvus_collection(collection_name, dim):\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "\n",
    "    fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.VARCHAR, descrition='ids', max_length=500, is_primary=True, auto_id=False),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='reverse image search')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    # create IVF_FLAT index for collection.\n",
    "    index_params = {\n",
    "        'metric_type':'L2',\n",
    "        'index_type':\"IVF_FLAT\",\n",
    "        'params':{\"nlist\":2048}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    return collection\n",
    "collection_name='question_answer_medical'\n",
    "collection = create_milvus_collection(collection_name, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0188bf",
   "metadata": {
    "id": "4c0188bf"
   },
   "source": [
    "### Load question embedding into Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a654fdc",
   "metadata": {
    "id": "0a654fdc"
   },
   "source": [
    "We first generate embedding from question text with [dpr](https://towhee.io/text-embedding/dpr) operator and insert the embedding into Milvus. Towhee provides a [method-chaining style API](https://towhee.readthedocs.io/en/main/index.html) so that users can assemble a data processing pipeline with operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from towhee import pipe, ops\n",
    "import numpy as np\n",
    "from towhee.datacollection import DataCollection\n",
    "from IPython.display import clear_output\n",
    "max_input_length = 500  # Maximum length allowed by the model\n",
    "collection_name='question_answer_medical'\n",
    "insert_pipe = (\n",
    "    pipe.input('id', 'question', 'answer')\n",
    "        .map('question', 'vec', lambda x: x[:max_input_length])  # Truncate the question if longer than 500 tokens\n",
    "        .map('vec', 'vec', ops.text_embedding.dpr(model_name='facebook/dpr-ctx_encoder-single-nq-base'))\n",
    "        .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
    "        .map(('id', 'vec'), 'insert_status', ops.ann_insert.milvus_client(host=REMOTE_SERVER, port='19530', collection_name=collection_name))\n",
    "        .output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174afca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Assuming you have a DataFrame named df\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    question = row['question']\n",
    "    # Truncate the question string if it exceeds the expected size for the model\n",
    "    if len(question) > 500:\n",
    "        row['question'] = question[:500]  # Truncate the question string if it exceeds 500 characters\n",
    "    insert_pipe(*row)\n",
    "# Clear the output\n",
    "#clear_output()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb3bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the DataFrame\n",
    "#for index, row in df.iterrows():\n",
    "#    insert_pipe(*row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbb2e1",
   "metadata": {
    "id": "1adbb2e1",
    "outputId": "b6dea15e-3ae8-4263-d6d3-7c1822b3ba19"
   },
   "outputs": [],
   "source": [
    "print('Total number of inserted data is {}.'.format(collection.num_entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35657d0",
   "metadata": {
    "id": "b35657d0"
   },
   "source": [
    "### Ask Question with Milvus and Towhee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02adfc",
   "metadata": {
    "id": "cd02adfc"
   },
   "source": [
    "Now that embedding for question dataset have been inserted into Milvus, we can ask question with Milvus and Towhee. Again, we use Towhee to load the input question, compute a embedding, and use it as a query in Milvus. Because Milvus only outputs IDs and distance values, we provide the `id_answers` dictionary to get the answers based on IDs and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b4b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from towhee import pipe, ops\n",
    "import numpy as np\n",
    "from towhee.datacollection import DataCollection\n",
    "from IPython.display import clear_output\n",
    "# Define the maximum input length for the question\n",
    "max_input_length = 512\n",
    "# Load the collection\n",
    "collection.load()\n",
    "# Create the combined pipe for question encoding and answer retrieval\n",
    "combined_pipe = (\n",
    "    pipe.input('question')\n",
    "        .map('question', 'vec', lambda x: x[:max_input_length])  # Truncate the question if longer than 512 tokens\n",
    "        .map('vec', 'vec', ops.text_embedding.dpr(model_name='facebook/dpr-ctx_encoder-single-nq-base'))\n",
    "        .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
    "        .map('vec', 'res', ops.ann_search.milvus_client(host=REMOTE_SERVER, port='19530', collection_name='question_answer', limit=1))\n",
    "        .map('res', 'answer', lambda x: [id_answer[int(i[0])] for i in x])\n",
    "        .output('question', 'answer')\n",
    ")\n",
    "# Perform the encoding and retrieval for a specific question\n",
    "ans = combined_pipe('What does abutment of the nerve root mean?')\n",
    "ans = DataCollection(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95913f05",
   "metadata": {
    "id": "95913f05",
    "outputId": "ae5ea48a-7bf2-4854-edb0-1ef018e77303"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "collection.load()\n",
    "ans_pipe = (\n",
    "    pipe.input('question')\n",
    "        .map('question', 'vec', ops.text_embedding.dpr(model_name=\"facebook/dpr-ctx_encoder-single-nq-base\"))\n",
    "        .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
    "        .map('vec', 'res', ops.ann_search.milvus_client(host=REMOTE_SERVER, port='19530', collection_name='question_answer', limit=1))\n",
    "        .map('res', 'answer', lambda x: [id_answer[int(i[0])] for i in x])\n",
    "        .output('question', 'answer')\n",
    ")\n",
    "ans = ans_pipe('What does abutment of the nerve root mean?')\n",
    "ans = DataCollection(ans)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d36b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb05a79",
   "metadata": {
    "id": "bfb05a79"
   },
   "source": [
    "Then we can get the answer about 'Is  Disability  Insurance  Required  By  Law?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a8f96",
   "metadata": {
    "id": "cb1a8f96",
    "outputId": "c19e3d2f-0e0b-47c5-ade8-85543543bdf8"
   },
   "outputs": [],
   "source": [
    "ans[0]['answer']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7dd10cdbe9a9c71f7e71741efd428241b5f9fa0fecdd29ae07a5706cd5ff8a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
