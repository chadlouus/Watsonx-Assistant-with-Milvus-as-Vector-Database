{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc029f17-95b7-4050-b650-b07a0d9e8e8f",
   "metadata": {},
   "source": [
    "# WatsonX.ai with Milvus and LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ffbe7",
   "metadata": {},
   "source": [
    "This guide demonstrates how to build an Watsonx.ai LLM-driven question-answering application with Milvus and LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882efd7",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "Create a Watson [Machine Learning (WML)](https://console.ng.bluemix.net/catalog/services/ibm-watson-machine-learning/) Service instance (a free plan is offered and information about how to create the instance can be found [here](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-service-instance.html?context=analytics))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1657c0d",
   "metadata": {},
   "source": [
    "### Install and import dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae39e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install pymilvus\n",
    "!pip install \"langchain==0.0.345\" \n",
    "!pip install wget \n",
    "!pip install sentence-transformers \n",
    "!pip install chromadb==0.3.22 \n",
    "!pip install \"ibm-watson-machine-learning>=1.0.335\" \n",
    "!pip install \"pydantic>=1.4.0,<2\" \n",
    "!pip install bs4\n",
    "!pip install ipywidgets\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8f1c23-5a74-4c35-84f1-f5706674b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install pymilvus \"langchain>=0.0.353\" openai tiktoken bs4 sentence_transformers \"ibm-watson-machine-learning>=1.0.327\"  humanize  pandas  rouge_score ibm_watsonx_ai  chromadb \"pydantic>=1.4.0,<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0657238e-cb2d-49ff-ae5f-7202b2795b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "COLLECTION_NAME = 'doc_qa_db'\n",
    "DIMENSION = 768\n",
    "MILVUS_PORT = \"19530\"\n",
    "REMOTE_SERVER = os.environ.get(\"REMOTE_SERVER\", \"localhost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745dd41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections\n",
    "connections.connect(host=REMOTE_SERVER, port=MILVUS_PORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be322cc9",
   "metadata": {},
   "source": [
    "If the collection already exists, drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd76635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import utility\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee846a0e-9406-471c-b545-be3dacfffee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.zilliz import Zilliz\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "loader = WebBaseLoader([\n",
    "    'https://milvus.io/docs/overview.md',\n",
    "    'https://milvus.io/docs/release_notes.md',\n",
    "    'https://milvus.io/docs/architecture_overview.md',\n",
    "    'https://milvus.io/docs/four_layers.md',\n",
    "    'https://milvus.io/docs/main_components.md',\n",
    "    'https://milvus.io/docs/data_processing.md',\n",
    "    'https://milvus.io/docs/bitset.md',\n",
    "    'https://milvus.io/docs/boolean.md',\n",
    "    'https://milvus.io/docs/consistency.md',\n",
    "    'https://milvus.io/docs/coordinator_ha.md',\n",
    "    'https://milvus.io/docs/replica.md',\n",
    "    'https://milvus.io/docs/knowhere.md',\n",
    "    'https://milvus.io/docs/schema.md',\n",
    "    'https://milvus.io/docs/dynamic_schema.md',\n",
    "    'https://milvus.io/docs/json_data_type.md',\n",
    "    'https://milvus.io/docs/metric.md',\n",
    "    'https://milvus.io/docs/partition_key.md',\n",
    "    'https://milvus.io/docs/multi_tenancy.md',\n",
    "    'https://milvus.io/docs/timestamp.md',\n",
    "    'https://milvus.io/docs/users_and_roles.md',\n",
    "    'https://milvus.io/docs/index.md',\n",
    "    'https://milvus.io/docs/disk_index.md',\n",
    "    'https://milvus.io/docs/scalar_index.md',\n",
    "    'https://milvus.io/docs/performance_faq.md',\n",
    "    'https://milvus.io/docs/product_faq.md',\n",
    "    'https://milvus.io/docs/operational_faq.md',\n",
    "    'https://milvus.io/docs/troubleshooting.md',\n",
    "])\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a7198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n",
    "texts  = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ded7be",
   "metadata": {},
   "source": [
    "After preparing the documents, the next step is to convert them into vector embeddings and save them in the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce6840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an embedding function\n",
    "# The performance of Elasticsearch may differ depending on the embedding model used.\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.vectorstores.milvus import Milvus\n",
    "#emb_func = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "875d04e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.vectorstores import Chroma\n",
    "#docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33e433b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_args={\"host\": REMOTE_SERVER, \"port\": MILVUS_PORT}\n",
    "vector_store = Milvus(\n",
    "    #embedding_function=emb_func,\n",
    "    embedding_function=embeddings,\n",
    "    connection_args=connection_args,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    drop_old=True,\n",
    ").from_documents(\n",
    "    texts,\n",
    "    #embedding=emb_func,\n",
    "    embedding=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_args=connection_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10568df0",
   "metadata": {},
   "source": [
    "And here is how you retrieve that stored collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0008ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = Milvus(\n",
    "    embeddings,\n",
    "    connection_args={\"host\": REMOTE_SERVER, \"port\": MILVUS_PORT},\n",
    "    collection_name=COLLECTION_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c383240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the main components of Milvus?\"\n",
    "docs = vector_db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f777b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Knowhere in the Milvus architecture.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7666bf7",
   "metadata": {},
   "source": [
    "To perform text-to-text similarity searches, use the following code snippet. The results will return the most relevant text in the document to the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f280f026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the main components of Milvus?\"\n",
    "docs = vector_store.similarity_search(query)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85487a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Knowhere in the Milvus architecture.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cedce8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will only documents related with the query\n",
    "query = \"What are the main components of Milvus?\"\n",
    "docs_search =vector_store.as_retriever(\n",
    ").get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b06366f",
   "metadata": {},
   "source": [
    "## watsonx API connection\n",
    "This cell defines the credentials required to work with watsonx API for Foundation Model inferencing.\n",
    "Action: Provide the IBM Cloud user API key. For details, see [documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui).\n",
    "\n",
    "Defining the project id\n",
    "The API requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id.\n",
    "\n",
    "Hint: You can find the project_id as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be Projects / <project name> /. Click on the <project name> link. Then get the project_id from Project's Manage tab (Project -> Manage -> General -> Details).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96fc98d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "try:\n",
    "    API_KEY = os.environ.get(\"API_KEY\")\n",
    "    project_id =os.environ.get(\"PROJECT_ID\")\n",
    "except KeyError:\n",
    "    API_KEY: input(\"Please enter your WML api key (hit enter): \")\n",
    "    project_id  = input(\"Please  project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5526be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": API_KEY  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822ae30",
   "metadata": {},
   "source": [
    "## Foundation Models on watsonx\n",
    "### Defining model\n",
    "You need to specify model_id that will be used for inferencing:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c13acb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "model_id = ModelTypes.GRANITE_13B_CHAT_V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a932cde",
   "metadata": {},
   "source": [
    "## Defining the model parameters\n",
    "We need to provide a set of model parameters that will influence the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b3e9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 100,\n",
    "    GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf437b7",
   "metadata": {},
   "source": [
    "LangChain CustomLLM wrapper for watsonx model\n",
    "Initialize the WatsonxLLM class from Langchain with defined parameters and ibm/granite-13b-chat-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5473db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import WatsonxLLM\n",
    "watsonx_granite = WatsonxLLM(\n",
    "    model_id=model_id.value,\n",
    "    url=credentials.get(\"url\"),\n",
    "    apikey=credentials.get(\"apikey\"),\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0cf15",
   "metadata": {},
   "source": [
    "Generate a retrieval-augmented response to a question\n",
    "Build the RetrievalQA (question answering chain) to automate the RAG task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d027d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e314c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Milvus', 'HuggingFaceEmbeddings'], vectorstore=<langchain.vectorstores.milvus.Milvus object at 0x7f33a3c87c10>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4786dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(llm=watsonx_granite,\n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c6223e",
   "metadata": {},
   "source": [
    "## Ask your question\n",
    "After preparing the documents, you can set up a chain to include them in a prompt. This will allow LLM to use the docs as a reference when preparing answers.\n",
    "Get questions from the previously loaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2bd4f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMilvus standalone includes three components:\\n\\n\\nMilvus: The core functional component.\\n\\nMetadata engine: Accesses and stores metadata of Milvus' internal components, including proxies, index nodes, and more.\\n\\nStorage engine: Responsible for data persistence for Milvus.\\n\\nMilvus cluster includes eight microservice components and three third-party dependencies. All microservices can be deployed on Kubernetes, independently from each other.\\n\\nMicroservice components\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the main components of Milvus?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "543d4e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18252287",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | watsonx_granite\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2623a75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " IVF_FLAT is an index type in Milvus that divides vector space into list clusters. At the default list value of 16,384, Milvus compares the distances between the target vector and the centroids of all 16,384 clusters to return probe nearest clusters. Then Milvus compares the distances between the target vector and the vectors in the selected clusters to get the nearest vectors. This method can be time-consuming when dealing with a large number of vectors.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"Explain IVF_FLAT in Milvus.\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
