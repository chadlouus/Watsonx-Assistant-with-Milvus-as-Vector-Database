{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4883e577",
      "metadata": {
        "id": "4883e577"
      },
      "source": [
        "## Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49110b91",
      "metadata": {
        "id": "49110b91"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0117995a",
      "metadata": {
        "id": "0117995a"
      },
      "source": [
        "First we need to install dependencies such as towhee, towhee.models and gradio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ba3850",
      "metadata": {
        "id": "c9ba3850",
        "outputId": "64286339-3996-4317-c6c6-6582e74a8eec"
      },
      "outputs": [],
      "source": [
        "! python -m pip install -q towhee towhee.models gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a90db0c5",
      "metadata": {
        "id": "a90db0c5"
      },
      "source": [
        "### Prepare the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1436a9c",
      "metadata": {
        "id": "d1436a9c",
        "outputId": "17c7f2ff-79fb-4b04-bcd5-79a048f8e4a9"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"ruslanmv/ai-medical-chatbot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa102b53",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = dataset[\"train\"]\n",
        "for i in range(1):\n",
        "    print(train_data[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39c9a880",
      "metadata": {},
      "source": [
        "For this demo let us choose the first 1000 dialogues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a765ead",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(train_data[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e840da8",
      "metadata": {},
      "outputs": [],
      "source": [
        "#df = df[[\"Patient\", \"Doctor\"]].rename(columns={\"Patient\": \"question\", \"Doctor\": \"answer\"})\n",
        "df = df[[\"Description\", \"Doctor\"]].rename(columns={\"Description\": \"question\", \"Doctor\": \"answer\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1979246b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add the 'ID' column as the first column\n",
        "df.insert(0, 'id', df.index)\n",
        "# Reset the index and drop the previous index column\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40c619b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "# Clean the 'question' and 'answer' columns\n",
        "df['question'] = df['question'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "df['answer'] = df['answer'].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
        "df['question'] = df['question'].str.replace('^Q.', '', regex=True)\n",
        "# Assuming your DataFrame is named df\n",
        "max_length = 500  # Due to our enbeeding model does not allow long strings\n",
        "df['question'] = df['question'].str.slice(0, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05077e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"question_answer.csv\", sep='\\t', encoding='utf-8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4abdc0a",
      "metadata": {
        "id": "c4abdc0a"
      },
      "source": [
        "**question_answer.csv**: a file containing question and the answer.\n",
        "\n",
        "Let's take a quick look:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d652efea",
      "metadata": {
        "id": "d652efea",
        "outputId": "ee6fdd36-8205-40d0-b7b2-701c09f153f7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Load the Pandas DataFrame\n",
        "df = pd.read_csv('question_answer.csv', sep='\\t', encoding='utf-8')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "309bfb43",
      "metadata": {
        "id": "309bfb43"
      },
      "source": [
        "To use the dataset to get answers, let's first define the dictionary:\n",
        "\n",
        "- `id_answer`: a dictionary of id and corresponding answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d98b309",
      "metadata": {
        "id": "4d98b309"
      },
      "outputs": [],
      "source": [
        "id_answer = df.set_index('id')['answer'].to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c5a0858",
      "metadata": {
        "id": "1c5a0858"
      },
      "source": [
        "### Create Milvus Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efb06a01",
      "metadata": {
        "id": "efb06a01"
      },
      "source": [
        "Before getting started, please make sure that you have started a [Milvus service](https://milvus.io/docs/install_standalone-docker.md). This notebook uses [milvus 2.2.10](https://milvus.io/docs/v2.2.x/install_standalone-docker.md) and [pymilvus 2.2.11](https://milvus.io/docs/release_notes.md#2210)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8048bf6c",
      "metadata": {
        "id": "8048bf6c"
      },
      "outputs": [],
      "source": [
        "! python -m pip install -q pymilvus==2.2.11"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87ba2b23",
      "metadata": {
        "id": "87ba2b23"
      },
      "source": [
        "Next to define the function `create_milvus_collection` to create collection in Milvus that uses the [L2 distance metric](https://milvus.io/docs/metric.md#Euclidean-distance-L2) and an [IVF_FLAT index](https://milvus.io/docs/index.md#IVF_FLAT)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "344421fe",
      "metadata": {},
      "source": [
        "### Setup Remote Server\n",
        "Here we should define the variable `REMOTE_SERVER` just created [here](https://github.com/ruslanmv/Watsonx-Assistant-with-Milvus-as-Vector-Database/blob/master/README.md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4105b31",
      "metadata": {},
      "outputs": [],
      "source": [
        "REMOTE_SERVER='50.17.92.90'\n",
        "LOCAL_SERVER='127.0.0.1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e15f49",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
        "connections.connect(host=REMOTE_SERVER, port='19530')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c19982",
      "metadata": {
        "id": "22c19982"
      },
      "outputs": [],
      "source": [
        "def create_milvus_collection(collection_name, dim):\n",
        "    if utility.has_collection(collection_name):\n",
        "        utility.drop_collection(collection_name)\n",
        "\n",
        "    fields = [\n",
        "    FieldSchema(name='id', dtype=DataType.VARCHAR, descrition='ids', max_length=500, is_primary=True, auto_id=False),\n",
        "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
        "    ]\n",
        "    schema = CollectionSchema(fields=fields, description='reverse image search')\n",
        "    collection = Collection(name=collection_name, schema=schema)\n",
        "\n",
        "    # create IVF_FLAT index for collection.\n",
        "    index_params = {\n",
        "        'metric_type':'L2',\n",
        "        'index_type':\"IVF_FLAT\",\n",
        "        'params':{\"nlist\":2048}\n",
        "    }\n",
        "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "    return collection\n",
        "dim_collection=768\n",
        "collection = create_milvus_collection('question_answers',dim_collection )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c0188bf",
      "metadata": {
        "id": "4c0188bf"
      },
      "source": [
        "### Load question embedding into Milvus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a654fdc",
      "metadata": {
        "id": "0a654fdc"
      },
      "source": [
        "We first generate embedding from question text with [dpr](https://towhee.io/text-embedding/dpr) operator and insert the embedding into Milvus. Towhee provides a [method-chaining style API](https://towhee.readthedocs.io/en/main/index.html) so that users can assemble a data processing pipeline with operators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6fa8061",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13b7beea",
      "metadata": {
        "id": "13b7beea",
        "outputId": "5152283b-025b-43f3-b0f3-215a174c285a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from towhee import pipe, ops\n",
        "import numpy as np\n",
        "from towhee.datacollection import DataCollection\n",
        "from IPython.display import clear_output\n",
        "insert_pipe = (\n",
        "    pipe.input('id', 'question', 'answer')\n",
        "        .map('question', 'vec', ops.text_embedding.dpr(model_name='facebook/dpr-ctx_encoder-single-nq-base'))\n",
        "        .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
        "        .map(('id', 'vec'), 'insert_status', ops.ann_insert.milvus_client(host=REMOTE_SERVER, port='19530', collection_name='question_answers'))\n",
        "        .output()\n",
        ")\n",
        "\n",
        "import csv\n",
        "with open('question_answer.csv', encoding='utf-8') as f:\n",
        "    reader = csv.reader(f)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        insert_pipe(*row)\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1adbb2e1",
      "metadata": {
        "id": "1adbb2e1",
        "outputId": "b6dea15e-3ae8-4263-d6d3-7c1822b3ba19"
      },
      "outputs": [],
      "source": [
        "print('Total number of inserted data is {}.'.format(collection.num_entities))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deb269f4",
      "metadata": {
        "id": "deb269f4"
      },
      "source": [
        "#### Explanation of Data Processing Pipeline\n",
        "\n",
        "Here is detailed explanation for each line of the code:\n",
        "\n",
        "`pipe.input('id', 'question', 'answer')`: Get three inputs, namely question's id, quesion's text and question's answer;\n",
        "\n",
        "`map('question', 'vec', ops.text_embedding.dpr(model_name='facebook/dpr-ctx_encoder-single-nq-base'))`: Use the `acebook/dpr-ctx_encoder-single-nq-base` model to generate the question embedding vector with the [dpr operator](https://towhee.io/text-embedding/dpr) in towhee hub;\n",
        "\n",
        "`map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))`: normalize the embedding vector;\n",
        "\n",
        "`map(('id', 'vec'), 'insert_status', ops.ann_insert.milvus_client(host='127.0.0.1', port='19530', collection_name='question_answer'))`: insert question embedding vector into Milvus;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b35657d0",
      "metadata": {
        "id": "b35657d0"
      },
      "source": [
        "### Ask Question with Milvus and Towhee"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd02adfc",
      "metadata": {
        "id": "cd02adfc"
      },
      "source": [
        "Now that embedding for question dataset have been inserted into Milvus, we can ask question with Milvus and Towhee. Again, we use Towhee to load the input question, compute a embedding, and use it as a query in Milvus. Because Milvus only outputs IDs and distance values, we provide the `id_answers` dictionary to get the answers based on IDs and display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95913f05",
      "metadata": {
        "id": "95913f05",
        "outputId": "ae5ea48a-7bf2-4854-edb0-1ef018e77303"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "collection.load()\n",
        "ans_pipe = (\n",
        "    pipe.input('question')\n",
        "        .map('question', 'vec', ops.text_embedding.dpr(model_name=\"facebook/dpr-ctx_encoder-single-nq-base\"))\n",
        "        .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
        "        .map('vec', 'res', ops.ann_search.milvus_client(host=REMOTE_SERVER, port='19530', collection_name='question_answer', limit=1))\n",
        "        .map('res', 'answer', lambda x: [id_answer[int(i[0])] for i in x])\n",
        "        .output('question', 'answer')\n",
        ")\n",
        "ans = ans_pipe('Is  Disability  Insurance  Required  By  Law?')\n",
        "ans = DataCollection(ans)\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d36b22",
      "metadata": {},
      "outputs": [],
      "source": [
        "ans.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb05a79",
      "metadata": {
        "id": "bfb05a79"
      },
      "source": [
        "Then we can get the answer about 'Is  Disability  Insurance  Required  By  Law?'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1a8f96",
      "metadata": {
        "id": "cb1a8f96",
        "outputId": "c19e3d2f-0e0b-47c5-ade8-85543543bdf8"
      },
      "outputs": [],
      "source": [
        "ans[0]['answer']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bef722",
      "metadata": {
        "id": "01bef722"
      },
      "source": [
        "## Release a Showcase"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c71cace8",
      "metadata": {
        "id": "c71cace8"
      },
      "source": [
        "We've done an excellent job on the core functionality of our question answering engine. Now it's time to build a showcase with interface. [Gradio](https://gradio.app/) is a great tool for building demos. With Gradio, we simply need to wrap the data processing pipeline via a `chat` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d42114",
      "metadata": {
        "id": "65d42114"
      },
      "outputs": [],
      "source": [
        "import towhee\n",
        "def chat(message, history):\n",
        "    history = history or []\n",
        "    ans_pipe = (\n",
        "        pipe.input('question')\n",
        "            .map('question', 'vec', ops.text_embedding.dpr(model_name=\"facebook/dpr-ctx_encoder-single-nq-base\"))\n",
        "            .map('vec', 'vec', lambda x: x / np.linalg.norm(x, axis=0))\n",
        "            .map('vec', 'res', ops.ann_search.milvus_client(host=REMOTE_SERVER, port='19530', collection_name='question_answer', limit=1))\n",
        "            .map('res', 'answer', lambda x: [id_answer[int(i[0])] for i in x])\n",
        "            .output('question', 'answer')\n",
        "    )\n",
        "    response = ans_pipe(message).get()[1][0]\n",
        "    history.append((message, response))\n",
        "    return history, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67ed9a25",
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio\n",
        "\n",
        "collection.load()\n",
        "chatbot = gradio.Chatbot()\n",
        "interface = gradio.Interface(\n",
        "    chat,\n",
        "    [\"text\", \"state\"],\n",
        "    [chatbot, \"state\"],\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "clear_output()\n",
        "interface.launch(inline=True, share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f7dd10cdbe9a9c71f7e71741efd428241b5f9fa0fecdd29ae07a5706cd5ff8a2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
